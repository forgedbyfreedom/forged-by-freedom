name: Build, Upload, and Sync Transcripts to Dashboard

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */6 * * *"  # every 6 hours

permissions:
  contents: write

env:
  GH_USER: forgedbyfreedom
  GH_PAT: ${{ secrets.FBF_PAT }}
  DASHBOARD_REPO: forgedbyfreedom/forged-by-freedom-st

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout thinkbig-transcripts repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          echo "üîß Installing dependencies..."
          python -m pip install --upgrade pip
          pip install requests openai beautifulsoup4 tqdm

      - name: Build master transcripts
        run: |
          echo "üìò Starting transcript builder..."
          python3 <<'PYCODE'
          import os, json
          from pathlib import Path
          from openai import OpenAI
          import time

          ROOT = Path(".")
          client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
          file_index = []

          for folder in ROOT.iterdir():
              if folder.is_dir() and folder.name.startswith("@"):
                  out_path = folder / "master_transcript1.txt"
                  with open(out_path, "w") as outfile:
                      for txt_file in folder.rglob("*.txt"):
                          with open(txt_file, "r", errors="ignore") as infile:
                              outfile.write(infile.read().strip() + "\n\n")
                  print(f"‚úÖ Finished {folder.name} ‚Üí {out_path}")

                  # Upload to OpenAI
                  with open(out_path, "rb") as f:
                      uploaded = client.files.create(file=f, purpose="assistants")
                      file_index.append({
                          "channel": folder.name,
                          "filename": out_path.name,
                          "file_id": uploaded.id,
                          "size": os.path.getsize(out_path),
                          "uploaded_at": time.strftime("%Y-%m-%d %H:%M:%S")
                      })
          
          with open("file_index.json", "w") as f:
              json.dump(file_index, f, indent=2)

          print("üéØ All transcripts processed & uploaded.")
          PYCODE

      - name: Commit and push updated transcripts to thinkbig-transcripts
        run: |
          echo "üíæ Committing updates..."
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add . || true
          git commit -m "Auto update transcripts and index [skip ci]" || echo "‚ÑπÔ∏è No changes."
          git push origin main || true

      - name: Sync master transcripts + index to dashboard repo
        run: |
          echo "üöÄ Syncing with dashboard repository..."
          git clone https://${GH_USER}:${GH_PAT}@github.com/${DASHBOARD_REPO}.git /tmp/dashboard
          mkdir -p /tmp/dashboard/transcripts
          cp */master_transcript1.txt /tmp/dashboard/transcripts/ 2>/dev/null || true
          cp file_index.json /tmp/dashboard/transcripts/

          cd /tmp/dashboard
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add transcripts/
          git commit -m "Sync master transcripts + file index from thinkbig-transcripts [skip ci]" || echo "‚ÑπÔ∏è No changes."
          git push origin main || true

name: Full Transcript Build + Sync + Assistant Update + Cleanup

on:
  workflow_dispatch:
  schedule:
    - cron: "0 */6 * * *"  # every 6 hours

permissions:
  contents: write

env:
  GH_USER: forgedbyfreedom
  GH_PAT: ${{ secrets.FBF_PAT }}
  DASHBOARD_REPO: forgedbyfreedom/forged-by-freedom-st
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  ASSISTANT_ID: asst_YOUR_ASSISTANT_ID_HERE  # üëà Replace with your real Assistant ID

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout thinkbig-transcripts repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          echo "üîß Installing dependencies..."
          python -m pip install --upgrade pip
          pip install requests openai beautifulsoup4 tqdm

      - name: Build and upload transcripts to OpenAI
        run: |
          echo "üìò Building and uploading transcripts..."
          python3 <<'PYCODE'
          import os, json, time
          from pathlib import Path
          from openai import OpenAI

          client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
          root = Path(".")
          file_index = []

          for folder in root.iterdir():
              if folder.is_dir() and folder.name.startswith("@"):
                  out_file = folder / "master_transcript1.txt"
                  with open(out_file, "w", encoding="utf-8") as outfile:
                      for txt in folder.rglob("*.txt"):
                          with open(txt, "r", encoding="utf-8", errors="ignore") as infile:
                              outfile.write(infile.read().strip() + "\n\n")
                  print(f"‚úÖ Combined transcript for {folder.name}")

                  with open(out_file, "rb") as f:
                      uploaded = client.files.create(file=f, purpose="assistants")
                      file_index.append({
                          "channel": folder.name,
                          "filename": out_file.name,
                          "file_id": uploaded.id,
                          "size_bytes": os.path.getsize(out_file),
                          "uploaded_at": time.strftime("%Y-%m-%d %H:%M:%S")
                      })

          with open("file_index.json", "w", encoding="utf-8") as f:
              json.dump(file_index, f, indent=2)

          print("üéØ Uploaded all transcripts and created file_index.json")
          PYCODE

      - name: Commit updated transcripts locally
        run: |
          echo "üíæ Committing updates to thinkbig-transcripts..."
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          if git diff --cached --quiet; then
            echo "‚ÑπÔ∏è No changes to commit. Skipping push."
          else
            git commit -m "Auto update transcripts + file index [skip ci]"
            git push origin main
          fi

      - name: Sync transcripts to dashboard repo
        run: |
          echo "üöÄ Syncing transcripts and index to dashboard repo..."
          git clone https://${GH_USER}:${GH_PAT}@github.com/${DASHBOARD_REPO}.git /tmp/dashboard
          mkdir -p /tmp/dashboard/transcripts
          cp */master_transcript1.txt /tmp/dashboard/transcripts/ 2>/dev/null || true
          cp file_index.json /tmp/dashboard/transcripts/

          cd /tmp/dashboard
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add transcripts/
          if git diff --cached --quiet; then
            echo "‚ÑπÔ∏è No new transcript changes to push to dashboard."
          else
            git commit -m "Sync master transcripts + index from thinkbig-transcripts [skip ci]"
            git push origin main
          fi

      - name: Update and clean OpenAI Assistant
        run: |
          echo "ü§ñ Updating Assistant and cleaning old files..."
          python3 <<'PYCODE'
          import os, json
          from openai import OpenAI

          api_key = os.getenv("OPENAI_API_KEY")
          asst_id = os.getenv("ASSISTANT_ID")
          if not api_key or not asst_id:
              print("‚ö†Ô∏è Missing OPENAI_API_KEY or ASSISTANT_ID ‚Äî skipping assistant update.")
              raise SystemExit(0)

          client = OpenAI(api_key=api_key)

          # Load new uploads
          with open("file_index.json", "r") as f:
              file_index = json.load(f)

          new_file_ids = [f["file_id"] for f in file_index]
          print(f"üîó Linking {len(new_file_ids)} files to assistant {asst_id}...")
          client.beta.assistants.update(asst_id, file_ids=new_file_ids)
          print("‚úÖ Assistant successfully updated.")

          # Cleanup older files with the same base name
          print("üßπ Checking for old transcript files to remove...")
          all_files = client.files.list().data
          keep_files = set(new_file_ids)
          deleted_count = 0

          for f in all_files:
              if f.id not in keep_files and f.filename == "master_transcript1.txt":
                  try:
                      client.files.delete(f.id)
                      deleted_count += 1
                  except Exception as e:
                      print(f"‚ö†Ô∏è Could not delete {f.id}: {e}")

          print(f"üßΩ Cleanup complete. Removed {deleted_count} outdated files.")
          PYCODE

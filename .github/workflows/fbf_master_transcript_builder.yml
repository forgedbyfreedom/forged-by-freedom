#!/usr/bin/env python3
"""
build_master_transcripts.py

Combines all channel transcript .txt files into master transcripts.

Features:
- Scans all subfolders in /transcripts/
- Groups by channel (folder name)
- Concatenates text files in alphabetical order
- Skips duplicate or empty files
- Outputs a master_transcript.txt per channel
- Produces a global manifest with totals
"""

import os
import json
import hashlib
from datetime import datetime

TRANSCRIPTS_DIR = "transcripts"
MANIFEST_PATH = os.path.join(TRANSCRIPTS_DIR, "master_manifest.json")


def file_md5(path: str) -> str:
    """Compute an MD5 hash of a file’s content."""
    with open(path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()


def get_channel_folders():
    """Return subfolders in /transcripts that represent channels."""
    folders = []
    for entry in os.listdir(TRANSCRIPTS_DIR):
        full = os.path.join(TRANSCRIPTS_DIR, entry)
        if os.path.isdir(full) and not entry.startswith("."):
            folders.append(full)
    return sorted(folders)


def build_channel_master(channel_path: str):
    """Combine all transcript files in a channel folder into one master transcript."""
    channel_name = os.path.basename(channel_path)
    output_file = os.path.join(channel_path, "master_transcript.txt")
    seen_hashes = set()
    parts = []
    total_words = 0
    files_processed = 0

    txt_files = sorted(
        [
            f
            for f in os.listdir(channel_path)
            if f.endswith(".txt") and not f.startswith("master_transcript")
        ]
    )

    if not txt_files:
        print(f"[WARN] No .txt files found in {channel_name}, skipping.")
        return None

    for filename in txt_files:
        path = os.path.join(channel_path, filename)
        try:
            with open(path, "r", encoding="utf-8", errors="ignore") as f:
                text = f.read().strip()
        except Exception as e:
            print(f"[WARN] Could not read {path}: {e}")
            continue

        if not text:
            print(f"[WARN] Empty file skipped: {filename}")
            continue

        file_hash = hashlib.md5(text.encode("utf-8")).hexdigest()
        if file_hash in seen_hashes:
            print(f"[WARN] Duplicate file skipped: {filename}")
            continue

        seen_hashes.add(file_hash)
        parts.append(f"\n\n=== {filename} ===\n{text}")
        total_words += len(text.split())
        files_processed += 1

    if not parts:
        print(f"[WARN] No valid text content found in {channel_name}. Skipping.")
        return None

    combined = "\n".join(parts)
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(combined)

    print(
        f"[OK] Created {output_file} — {files_processed} files combined, {total_words:,} words."
    )
    return {
        "channel": channel_name,
        "files": files_processed,
        "words": total_words,
        "output": output_file,
        "updated": datetime.now().isoformat(),
    }


def build_all_channels():
    """Rebuild all master transcripts in all channel folders."""
    os.makedirs(TRANSCRIPTS_DIR, exist_ok=True)
    manifest = []

    for channel_folder in get_channel_folders():
        info = build_channel_master(channel_folder)
        if info:
            manifest.append(info)

    if not manifest:
        print("[WARN] No channels processed — verify your transcripts directory.")
        return

    with open(MANIFEST_PATH, "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2)

    total_channels = len(manifest)
    total_episodes = sum(c["files"] for c in manifest)
    total_words = sum(c["words"] for c in manifest)

    print("\n[SUMMARY]")
    print(f"Channels processed: {total_channels}")
    print(f"Total files combined: {total_episodes}")
    print(f"Total words combined: {total_words:,}")
    print(f"Manifest saved to: {MANIFEST_PATH}")


if __name__ == "__main__":
    build_all_channels()

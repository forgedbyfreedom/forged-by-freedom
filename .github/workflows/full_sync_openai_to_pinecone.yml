"""
full_sync_openai_to_pinecone.py
---------------------------------------------------------
Performs a full synchronization between OpenAI file storage
and your Pinecone vector database.
Auto-fixes old Pinecone SDK issues and runs cleanly in CI.
---------------------------------------------------------
"""

import os
import sys
import time
import json
import importlib
import subprocess
from pathlib import Path
from tqdm import tqdm

# ==========================================================
# üß© AUTO-FIX OLD PINECONE INSTALLATIONS
# ==========================================================
def ensure_pinecone_sdk():
    try:
        import pinecone
        if not hasattr(pinecone, "Pinecone"):
            raise ImportError("Old pinecone-client detected.")
        return pinecone
    except Exception:
        print("‚ö†Ô∏è  Detected old or missing Pinecone client. Replacing with new SDK...")
        subprocess.run([sys.executable, "-m", "pip", "uninstall", "-y", "pinecone-client", "pinecone"])
        subprocess.run([sys.executable, "-m", "pip", "install", "--no-cache-dir", "pinecone"])
        importlib.invalidate_caches()
        import pinecone
        return pinecone


pinecone = ensure_pinecone_sdk()

# ==========================================================
# üîê ENVIRONMENT VARIABLES
# ==========================================================
from dotenv import load_dotenv

load_dotenv()

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not PINECONE_API_KEY or not OPENAI_API_KEY:
    raise EnvironmentError("‚ùå Missing required environment variables: PINECONE_API_KEY or OPENAI_API_KEY.")

# ==========================================================
# üîó IMPORT LIBRARIES
# ==========================================================
from openai import OpenAI

# Connect clients
client = OpenAI(api_key=OPENAI_API_KEY)
pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)

# Define index configuration
INDEX_NAME = "forged-by-freedom"
namespace = "openai-files"

# ==========================================================
# üß± ENSURE INDEX EXISTS
# ==========================================================
existing_indexes = [idx["name"] for idx in pc.list_indexes()]
if INDEX_NAME not in existing_indexes:
    print(f"ü™∂ Creating Pinecone index: {INDEX_NAME}")
    pc.create_index(
        name=INDEX_NAME,
        dimension=1536,  # for text-embedding-3-small / large
        metric="cosine",
        spec=pinecone.ServerlessSpec(cloud="aws", region="us-east-1")
    )

index = pc.Index(INDEX_NAME)

# ==========================================================
# üóÇ FETCH OPENAI FILES
# ==========================================================
print("üìÇ Retrieving OpenAI files...")
files = client.files.list()
files_data = [f for f in files.data if f.purpose == "fine-tune" or f.purpose == "assistants"]

if not files_data:
    print("‚ö†Ô∏è No OpenAI files found for sync.")
    sys.exit(0)

print(f"‚úÖ Found {len(files_data)} OpenAI files to sync.")

# ==========================================================
# üß† LOAD AND EMBED FILES
# ==========================================================
def get_embedding(text: str):
    """Helper to generate embeddings using OpenAI."""
    try:
        emb = client.embeddings.create(model="text-embedding-3-small", input=text)
        return emb.data[0].embedding
    except Exception as e:
        print(f"‚ö†Ô∏è Embedding error: {e}")
        return None


uploaded_count = 0
skipped = 0

for f in tqdm(files_data, desc="üîÅ Syncing to Pinecone"):
    try:
        file_content = client.files.retrieve_content(f.id)
        text = file_content.decode("utf-8") if isinstance(file_content, bytes) else str(file_content)

        # Chunk large files
        chunks = [text[i:i + 2000] for i in range(0, len(text), 2000)]

        vectors = []
        for i, chunk in enumerate(chunks):
            emb = get_embedding(chunk)
            if emb:
                vectors.append({
                    "id": f"{f.id}_{i}",
                    "values": emb,
                    "metadata": {"filename": f.filename, "chunk": i}
                })

        if vectors:
            index.upsert(vectors=vectors, namespace=namespace)
            uploaded_count += 1
        else:
            skipped += 1

    except Exception as e:
        print(f"‚ö†Ô∏è Failed to sync {f.filename}: {e}")
        skipped += 1
        continue

# ==========================================================
# üìä FINAL SUMMARY
# ==========================================================
stats = index.describe_index_stats()
vector_count = stats["total_vector_count"]

print("\nüéØ SYNC COMPLETE")
print(f"‚úÖ Uploaded files: {uploaded_count}")
print(f"‚ö†Ô∏è Skipped files: {skipped}")
print(f"üìä Total vectors in index '{INDEX_NAME}': {vector_count}\n")

import os
import glob
import openai
import pinecone
from tqdm import tqdm

# Load environment variables
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")

if not OPENAI_API_KEY or not PINECONE_API_KEY:
    raise RuntimeError("‚ùå Missing required environment variables (OpenAI or Pinecone key).")

openai.api_key = OPENAI_API_KEY

print("‚úÖ Correct Pinecone SDK already installed")

pinecone.init(api_key=PINECONE_API_KEY)
index_name = "forged-freedom-ai"

# Create index if needed
if index_name not in pinecone.list_indexes().names():
    pinecone.create_index(index_name, dimension=3072)
index = pinecone.Index(index_name)

# Find all transcript files
transcript_files = sorted(glob.glob("transcripts/*.txt"))
print(f"üìö Found {len(transcript_files)} transcript files to sync")

def chunk_text(text, max_chars=12000):
    """Split long text into smaller chunks."""
    return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]

for filepath in tqdm(transcript_files, desc="Uploading transcripts"):
    filename = os.path.basename(filepath)
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read().strip()

    chunks = chunk_text(text)
    all_vectors = []

    for idx, chunk in enumerate(chunks):
        try:
            embedding = openai.embeddings.create(
                input=chunk,
                model="text-embedding-3-large"
            ).data[0].embedding
            all_vectors.append({
                "id": f"{filename}-{idx}",
                "values": embedding,
                "metadata": {"source": filename, "chunk": idx}
            })
        except Exception as e:
            print(f"‚ö†Ô∏è Skipped chunk {idx} from {filename}: {e}")

    if all_vectors:
        index.upsert(vectors=all_vectors)
        print(f"‚úÖ Uploaded {len(all_vectors)} chunks from {filename}")

print("üéâ All transcripts uploaded successfully to Pinecone!")
